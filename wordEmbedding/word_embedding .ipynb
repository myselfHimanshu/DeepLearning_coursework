{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use word embedding layers for deep learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding provide dense representation and relative meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = [1,1,1,1,1,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45, 28], [34, 26], [40, 19], [38, 26], [10], [9], [8, 19], [49, 34], [8, 26], [6, 11, 28, 18]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pad the documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45 28  0  0]\n",
      " [34 26  0  0]\n",
      " [40 19  0  0]\n",
      " [38 26  0  0]\n",
      " [10  0  0  0]\n",
      " [ 9  0  0  0]\n",
      " [ 8 19  0  0]\n",
      " [49 34  0  0]\n",
      " [ 8 26  0  0]\n",
      " [ 6 11 28 18]]\n"
     ]
    }
   ],
   "source": [
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s - loss: 0.6919 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s - loss: 0.6907 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s - loss: 0.6896 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s - loss: 0.6884 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s - loss: 0.6873 - acc: 0.6000\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s - loss: 0.6861 - acc: 0.6000\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s - loss: 0.6849 - acc: 0.6000\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s - loss: 0.6838 - acc: 0.6000\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s - loss: 0.6826 - acc: 0.6000\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s - loss: 0.6814 - acc: 0.6000\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s - loss: 0.6802 - acc: 0.6000\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s - loss: 0.6791 - acc: 0.6000\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s - loss: 0.6779 - acc: 0.7000\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s - loss: 0.6767 - acc: 0.7000\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s - loss: 0.6755 - acc: 0.7000\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s - loss: 0.6743 - acc: 0.7000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s - loss: 0.6731 - acc: 0.7000\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s - loss: 0.6719 - acc: 0.7000\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s - loss: 0.6707 - acc: 0.7000\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s - loss: 0.6695 - acc: 0.7000\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s - loss: 0.6682 - acc: 0.7000\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s - loss: 0.6670 - acc: 0.7000\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s - loss: 0.6658 - acc: 0.7000\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s - loss: 0.6645 - acc: 0.7000\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s - loss: 0.6632 - acc: 0.7000\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s - loss: 0.6619 - acc: 0.7000\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s - loss: 0.6607 - acc: 0.7000\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s - loss: 0.6594 - acc: 0.7000\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s - loss: 0.6580 - acc: 0.7000\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s - loss: 0.6567 - acc: 0.8000\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s - loss: 0.6554 - acc: 0.8000\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s - loss: 0.6540 - acc: 0.8000\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s - loss: 0.6527 - acc: 0.8000\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s - loss: 0.6513 - acc: 0.8000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s - loss: 0.6499 - acc: 0.8000\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s - loss: 0.6485 - acc: 0.8000\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s - loss: 0.6471 - acc: 0.8000\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s - loss: 0.6457 - acc: 0.8000\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s - loss: 0.6442 - acc: 0.8000\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s - loss: 0.6428 - acc: 0.8000\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s - loss: 0.6413 - acc: 0.8000\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s - loss: 0.6398 - acc: 0.8000\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s - loss: 0.6383 - acc: 0.8000\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s - loss: 0.6368 - acc: 0.8000\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s - loss: 0.6353 - acc: 0.8000\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s - loss: 0.6337 - acc: 0.8000\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s - loss: 0.6322 - acc: 0.8000\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s - loss: 0.6306 - acc: 0.8000\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s - loss: 0.6291 - acc: 0.8000\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s - loss: 0.6275 - acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f787ed4bdd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 89.999998\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : %f\"%(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pre trained GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = [1,1,1,1,1,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "#integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "#pad documents to max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "\n",
    "f = open('../../../myWork/kaggle/DATASET/glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Loaded %s word vectors.'%len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a weight matrix for words in training docs\n",
    "embeddings_matrix = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embeddings_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 4, 100)            1500      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 1,901\n",
      "Trainable params: 401\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s - loss: 0.7244 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s - loss: 0.7057 - acc: 0.6000\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s - loss: 0.6878 - acc: 0.6000\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s - loss: 0.6707 - acc: 0.6000\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s - loss: 0.6545 - acc: 0.6000\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s - loss: 0.6391 - acc: 0.6000\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s - loss: 0.6246 - acc: 0.6000\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s - loss: 0.6109 - acc: 0.8000\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s - loss: 0.5980 - acc: 0.8000\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s - loss: 0.5858 - acc: 0.8000\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s - loss: 0.5745 - acc: 0.8000\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s - loss: 0.5638 - acc: 0.8000\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s - loss: 0.5537 - acc: 0.9000\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s - loss: 0.5442 - acc: 0.9000\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s - loss: 0.5352 - acc: 0.9000\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s - loss: 0.5266 - acc: 0.9000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s - loss: 0.5184 - acc: 0.9000\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s - loss: 0.5106 - acc: 0.9000\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s - loss: 0.5031 - acc: 0.9000\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s - loss: 0.4958 - acc: 0.9000\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s - loss: 0.4887 - acc: 0.9000\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s - loss: 0.4819 - acc: 0.9000\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s - loss: 0.4752 - acc: 0.9000\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s - loss: 0.4686 - acc: 0.9000\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s - loss: 0.4622 - acc: 0.9000\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s - loss: 0.4559 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s - loss: 0.4497 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s - loss: 0.4437 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s - loss: 0.4377 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s - loss: 0.4319 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s - loss: 0.4261 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s - loss: 0.4205 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s - loss: 0.4150 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s - loss: 0.4096 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s - loss: 0.4042 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s - loss: 0.3990 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s - loss: 0.3939 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s - loss: 0.3889 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s - loss: 0.3840 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s - loss: 0.3792 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s - loss: 0.3745 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s - loss: 0.3698 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s - loss: 0.3653 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s - loss: 0.3608 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s - loss: 0.3565 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s - loss: 0.3522 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s - loss: 0.3479 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s - loss: 0.3438 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s - loss: 0.3397 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s - loss: 0.3357 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f785f28e0f0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s\n",
      "Accuracy : 100.000000\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=1)\n",
    "print(\"Accuracy : %f\"%(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
