{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "with open('data/LabelledData.txt','r') as f:\n",
    "    for line in f:\n",
    "        text, label = map(str,line.split(\",,,\"))\n",
    "        texts.append(text.strip())\n",
    "        labels.append(label.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for text, label in zip(texts[:10], labels[:10]):\n",
    "#    print(text,\" -->\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    text = re.sub(r\"\\b's\\b\",\"is\",text)\n",
    "    text = re.sub(r\"[^a-z?\\.]\",\" \",text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = [pre_process(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how did serfdom develop in and then leave russia ?  --> unknown\n",
      "what films featured the character popeye doyle ?  --> what\n",
      "how can i find a list of celebrities   real names ?  --> unknown\n",
      "what fowl grabs the spotlight after the chinese year of the monkey ?  --> what\n",
      "what is the full form of .com ?  --> what\n",
      "what contemptible scoundrel stole the cork from my lunch ?  --> what\n",
      "what team did baseball  s st. louis browns become ?  --> what\n",
      "what is the oldest profession ?  --> what\n",
      "what are liver enzymes ?  --> what\n",
      "name the scar faced bounty hunter of the old west .  --> unknown\n"
     ]
    }
   ],
   "source": [
    "for text, label in zip(processed_texts[:10], labels[:10]):\n",
    "    print(text,\" -->\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(texts)\n",
    "y = np.array(labels, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'affirmation': 104, 'unknown': 272, 'what': 609, 'when': 96, 'who': 402}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import os, sys\n",
    "\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model, Sequential\n",
    "from keras import utils\n",
    "from keras.layers import concatenate, Activation\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 45\n",
    "MAX_NUM_WORDS = 50\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = X[indices]\n",
    "labels = y[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data[:-num_validation_samples]\n",
    "train_y = labels[:-num_validation_samples]\n",
    "test_x = data[-num_validation_samples:]\n",
    "test_y = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_y)\n",
    "y_train = encoder.transform(train_y)\n",
    "y_test = encoder.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "x_train = tokenizer.texts_to_matrix(train_x)\n",
    "x_test = tokenizer.texts_to_matrix(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1335, 50)\n",
      "x_test shape: (148, 50)\n",
      "y_train shape: (1335, 5)\n",
      "y_test shape: (148, 5)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3414 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               26112     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 28,677\n",
      "Trainable params: 28,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(MAX_NUM_WORDS,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights/best_weights.{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1201 samples, validate on 134 samples\n",
      "Epoch 1/5\n",
      "1201/1201 [==============================] - 0s 395us/step - loss: 1.1727 - acc: 0.6295 - val_loss: 0.7825 - val_acc: 0.7761\n",
      "Epoch 2/5\n",
      "1201/1201 [==============================] - 0s 122us/step - loss: 0.6197 - acc: 0.8435 - val_loss: 0.3970 - val_acc: 0.9328\n",
      "Epoch 3/5\n",
      "1201/1201 [==============================] - 0s 140us/step - loss: 0.3600 - acc: 0.9351 - val_loss: 0.2271 - val_acc: 0.9403\n",
      "Epoch 4/5\n",
      "1201/1201 [==============================] - 0s 145us/step - loss: 0.2454 - acc: 0.9484 - val_loss: 0.1569 - val_acc: 0.9478\n",
      "Epoch 5/5\n",
      "1201/1201 [==============================] - 0s 168us/step - loss: 0.2110 - acc: 0.9509 - val_loss: 0.1322 - val_acc: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d49961e10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 85us/step\n",
      "Test score: 0.17618592687555262\n",
      "Test accuracy: 0.9594594562375868\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels = encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what time do you go to the school ? ...\n",
      "Actual label:when\n",
      "Predicted label: what\n",
      "\n",
      "when is boxing day ? ...\n",
      "Actual label:what\n",
      "Predicted label: when\n",
      "\n",
      "when reading classified ads , what does eenty : other stand for ? ...\n",
      "Actual label:when\n",
      "Predicted label: what\n",
      "\n",
      "are these lead free ? ...\n",
      "Actual label:affirmation\n",
      "Predicted label: unknown\n",
      "\n",
      "what time of day did emperor hirohito die ? ...\n",
      "Actual label:when\n",
      "Predicted label: what\n",
      "\n",
      "what time does the flight leave ? ...\n",
      "Actual label:when\n",
      "Predicted label: what\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(148):\n",
    "    prediction = model.predict(np.array([x_test[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]\n",
    "    if test_y[i]!=predicted_label:\n",
    "        print(test_x[i][:100], \"...\")\n",
    "        print('Actual label:' + test_y[i])\n",
    "        print(\"Predicted label: \" + predicted_label + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
