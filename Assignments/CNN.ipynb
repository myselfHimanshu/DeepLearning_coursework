{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "with open('data/LabelledData.txt','r') as f:\n",
    "    for line in f:\n",
    "        text, label = map(str,line.split(\",,,\"))\n",
    "        texts.append(text.strip())\n",
    "        labels.append(label.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for text, label in zip(texts[:10], labels[:10]):\n",
    "#    print(text,\" -->\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    text = re.sub(r\"\\b's\\b\",\"is\",text)\n",
    "    text = re.sub(r\"[^a-z?\\.]\",\" \",text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = [pre_process(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how did serfdom develop in and then leave russia ?  --> unknown\n",
      "what films featured the character popeye doyle ?  --> what\n",
      "how can i find a list of celebrities   real names ?  --> unknown\n",
      "what fowl grabs the spotlight after the chinese year of the monkey ?  --> what\n",
      "what is the full form of .com ?  --> what\n",
      "what contemptible scoundrel stole the cork from my lunch ?  --> what\n",
      "what team did baseball  s st. louis browns become ?  --> what\n",
      "what is the oldest profession ?  --> what\n",
      "what are liver enzymes ?  --> what\n",
      "name the scar faced bounty hunter of the old west .  --> unknown\n"
     ]
    }
   ],
   "source": [
    "for text, label in zip(processed_texts[:10], labels[:10]):\n",
    "    print(text,\" -->\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(texts)\n",
    "y = np.array(labels, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'affirmation': 104, 'unknown': 272, 'what': 609, 'when': 96, 'who': 402}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/anaconda3/envs/deeplearning/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import os, sys\n",
    "\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model, Sequential\n",
    "from keras import utils\n",
    "from keras.layers import concatenate, Activation\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 45\n",
    "MAX_NUM_WORDS = 1000\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = X[indices]\n",
    "labels = y[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data[:-num_validation_samples]\n",
    "train_y = labels[:-num_validation_samples]\n",
    "test_x = data[-num_validation_samples:]\n",
    "test_y = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_y)\n",
    "y_train = encoder.transform(train_y)\n",
    "y_test = encoder.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "x_train = tokenizer.texts_to_sequences(train_x)\n",
    "x_test = tokenizer.texts_to_sequences(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3434 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(x_test, maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('x_train shape:', x_train.shape)\n",
    "#print('x_test shape:', x_test.shape)\n",
    "#print('y_train shape:', y_train.shape)\n",
    "#print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/himanshu/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 45)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 45, 100)      343500      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 44, 100)      20100       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 43, 100)      30100       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 100)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 100)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          51456       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            1285        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 446,441\n",
      "Trainable params: 446,441\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = Embedding(vocab_size, 100)(sequence_input)\n",
    "\n",
    "x1 = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(embedded_sequences)\n",
    "x1 = GlobalMaxPooling1D()(x1)\n",
    "\n",
    "x2 = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(embedded_sequences)\n",
    "x2 = GlobalMaxPooling1D()(x2)\n",
    "\n",
    "merged = concatenate([x1, x2], axis=1)\n",
    "merged = Dense(256, activation='relu')(merged)\n",
    "merged = Dropout(0.5)(merged)\n",
    "merged = Dense(5)(merged)\n",
    "output = Activation('sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[sequence_input], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights/CNN_weights.{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1201 samples, validate on 134 samples\n",
      "Epoch 1/5\n",
      "1201/1201 [==============================] - 2s 2ms/step - loss: 0.5481 - acc: 0.7782 - val_loss: 0.4234 - val_acc: 0.8000\n",
      "Epoch 2/5\n",
      "1201/1201 [==============================] - 1s 1ms/step - loss: 0.3609 - acc: 0.8656 - val_loss: 0.2709 - val_acc: 0.9254\n",
      "Epoch 3/5\n",
      "1201/1201 [==============================] - 1s 1ms/step - loss: 0.2094 - acc: 0.9326 - val_loss: 0.1624 - val_acc: 0.9388\n",
      "Epoch 4/5\n",
      "1201/1201 [==============================] - 1s 1ms/step - loss: 0.1429 - acc: 0.9495 - val_loss: 0.1174 - val_acc: 0.9627\n",
      "Epoch 5/5\n",
      "1201/1201 [==============================] - 1s 1ms/step - loss: 0.1010 - acc: 0.9645 - val_loss: 0.0837 - val_acc: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4e57b1b38>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 285us/step\n",
      "Test score: 0.08441820277555569\n",
      "Test accuracy: 0.9702702841243228\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=64, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels = encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when not adventuring on rann , what does adam strange call his profession ? ...\n",
      "Actual label:when\n",
      "Predicted label: what\n",
      "\n",
      "when did the berlin wall go up ? ...\n",
      "Actual label:unknown\n",
      "Predicted label: when\n",
      "\n",
      "when did rococo painting and architecture flourish ? ...\n",
      "Actual label:what\n",
      "Predicted label: when\n",
      "\n",
      "is there a lag time after you take it out of the box before it starts to work ? ...\n",
      "Actual label:affirmation\n",
      "Predicted label: unknown\n",
      "\n",
      "when superman needs to get away from it all , where does he go ? ...\n",
      "Actual label:when\n",
      "Predicted label: unknown\n",
      "\n",
      "when it 's time to relax , what one beer stands clear ? ...\n",
      "Actual label:when\n",
      "Predicted label: what\n",
      "\n",
      "what soap was touted as being `` for people who like people '' ? ...\n",
      "Actual label:what\n",
      "Predicted label: who\n",
      "\n",
      "when is boxing day ? ...\n",
      "Actual label:what\n",
      "Predicted label: when\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(148):\n",
    "    prediction = model.predict(np.array([x_test[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]\n",
    "    if test_y[i]!=predicted_label:\n",
    "        print(test_x[i][:100], \"...\")\n",
    "        print('Actual label:' + test_y[i])\n",
    "        print(\"Predicted label: \" + predicted_label + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess there are some sentences which have been wrongly tagged in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
